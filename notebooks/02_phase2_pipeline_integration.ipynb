{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742d251",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Phase 2: Pipeline Integration Test\n",
    "# Testing the complete YOLO+CLIP zero-shot detection pipeline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')  # Add src to path\n",
    "\n",
    "from src.pipeline import ZeroShotDetectionPipeline\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=== Phase 2: Pipeline Integration Test ===\")\n",
    "\n",
    "# 1. Initialize the integrated pipeline\n",
    "print(\"1. Initializing Zero-Shot Detection Pipeline...\")\n",
    "pipeline = ZeroShotDetectionPipeline(yolo_model='yolov8n.pt')\n",
    "\n",
    "# 2. Download test image if not exists\n",
    "test_url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "test_image_path = \"../test_image.jpg\"\n",
    "\n",
    "if not os.path.exists(test_image_path):\n",
    "    print(\"2. Downloading test image...\")\n",
    "    img_data = requests.get(test_image_path).content\n",
    "    with open(test_image_path, 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "\n",
    "# 3. Define what we want to detect - we can add ANY object!\n",
    "print(\"3. Defining detection targets...\")\n",
    "detection_targets = [\n",
    "    \"bus\", \"person\", \"car\", \"traffic light\", \n",
    "    \"stop sign\", \"building\", \"tree\", \"road\"\n",
    "]\n",
    "\n",
    "print(f\"   Looking for: {', '.join(detection_targets)}\")\n",
    "\n",
    "# 4. Run the complete pipeline\n",
    "print(\"4. Running zero-shot detection pipeline...\")\n",
    "results = pipeline.detect(test_image_path, detection_targets)\n",
    "\n",
    "# 5. Print comprehensive results\n",
    "print(f\"\\n=== DETECTION RESULTS ===\")\n",
    "print(f\"Image: {results['image_path']}\")\n",
    "print(f\"Target objects: {', '.join(results['original_prompts'])}\")\n",
    "print(f\"Found {len(results['detections'])} objects:\\n\")\n",
    "\n",
    "for i, detection in enumerate(results['detections']):\n",
    "    print(f\"Object {i+1}:\")\n",
    "    print(f\"  Position: {detection['box'].astype(int)}\")\n",
    "    print(f\"  Classification: '{detection['clip_class']}'\")\n",
    "    print(f\"  YOLO Confidence: {detection['yolo_confidence']:.3f}\")\n",
    "    print(f\"  CLIP Confidence: {detection['clip_confidence']:.3f}\")\n",
    "    print()\n",
    "\n",
    "# 6. Save detailed visualization\n",
    "print(\"5. Generating visualization...\")\n",
    "os.makedirs('../results/visualizations', exist_ok=True)\n",
    "pipeline.visualize_detections(results, '../results/visualizations/phase2_detections.jpg')\n",
    "\n",
    "print(\"\\nâœ… Phase 2 completed successfully!\")\n",
    "print(\"   - Integrated pipeline is working\")\n",
    "print(\"   - Processing ALL detections with CLIP\")\n",
    "print(\"   - Prompt engineering implemented\")\n",
    "print(\"   - Comprehensive visualization created\")\n",
    "print(\"   - Ready for real zero-shot detection!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
